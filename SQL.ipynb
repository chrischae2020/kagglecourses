{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with SQL and BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1035661e8528>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_crime\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_crime\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need here to figure out the answer\n",
    "table = list(client.list_tables(dataset))\n",
    "for t in table:\n",
    "    print(t.table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"crime\" table\n",
    "table_ref = dataset_ref.table(\"crime\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Print information on all the columns in the \"crime\" table in the \"chicago_crime\" dataset\n",
    "print(table.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select, From, Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"openaq\" dataset\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"global_air_quality\" table\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"global_air_quality\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select countries with units of \"ppm\"\n",
    "first_query = \"\"\"\n",
    "              SELECT country\n",
    "              FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "              WHERE unit = \"ppm\"\n",
    "              \"\"\" # Your code goes here\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "first_query_job = client.query(first_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "first_results = first_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(first_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select all columns where pollution levels are exactly 0\n",
    "zero_pollution_query = \"\"\"\n",
    "                       SELECT *\n",
    "                       FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "                       WHERE value = 0\n",
    "                       \"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(zero_pollution_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query and return a pandas DataFrame\n",
    "zero_pollution_results = query_job.to_dataframe()\n",
    "\n",
    "print(zero_pollution_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group By, Having, Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"hacker_news\" dataset\n",
    "dataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"comments\" table\n",
    "table_ref = dataset_ref.table(\"comments\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"comments\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select prolific commenters and post counts\n",
    "prolific_commenters_query = \"\"\"\n",
    "                            SELECT author, COUNT(1) AS NumPosts\n",
    "                            FROM `bigquery-public-data.hacker_news.comments`\n",
    "                            GROUP BY author\n",
    "                            HAVING COUNT(1) > 10000\n",
    "                            \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(prolific_commenters_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "prolific_commenters = query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(prolific_commenters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your query here and figure out the answer\n",
    "q = \"\"\"\n",
    "    SELECT COUNT(1) as num_deleted_posts\n",
    "    FROM `bigquery-public-data.hacker_news.comments`\n",
    "    WHERE deleted = True\n",
    "    \"\"\"\n",
    "\n",
    "# Set up the query\n",
    "query_job = client.query(q)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "deleted_posts = query_job.to_dataframe()\n",
    "\n",
    "# View results\n",
    "print(deleted_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"world_bank_intl_education\" dataset\n",
    "dataset_ref = client.dataset(\"world_bank_intl_education\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"international_education\" table\n",
    "table_ref = dataset_ref.table(\"international_education\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"international_education\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "country_spend_pct_query = \"\"\"\n",
    "                          SELECT country_name, AVG(value) AS avg_ed_spending_pct\n",
    "                          FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "                          WHERE indicator_code = 'SE.XPD.TOTL.GD.ZS' and year >= 2010 and year <= 2017\n",
    "                          GROUP BY country_name\n",
    "                          ORDER BY avg_ed_spending_pct DESC\n",
    "                          \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "country_spend_pct_query_job = client.query(country_spend_pct_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "country_spending_results = country_spend_pct_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(country_spending_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "code_count_query = \"\"\"\n",
    "                   SELECT indicator_code, indicator_name, COUNT(1) AS num_rows\n",
    "                   FROM `bigquery-public-data.world_bank_intl_education.international_education`\n",
    "                   WHERE year = 2016\n",
    "                   GROUP BY indicator_code, indicator_name\n",
    "                   HAVING COUNT(1) >= 175\n",
    "                   ORDER BY num_rows DESC\n",
    "                   \"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "code_count_query_job = client.query(code_count_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "code_count_results = code_count_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(code_count_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As and With"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_taxi_trips\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the tables in the dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there is only one!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"taxi_trips\" table\n",
    "table_ref = dataset_ref.table(\"taxi_trips\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"taxi_trips\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_per_year_query = \"\"\"\n",
    "                       SELECT EXTRACT(YEAR FROM trip_start_timestamp) AS year, \n",
    "                              COUNT(1) AS num_trips\n",
    "                       FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                       GROUP BY year\n",
    "                       ORDER BY year\n",
    "                       \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "rides_per_year_query_job = client.query(rides_per_year_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "rides_per_year_result = rides_per_year_query_job.to_dataframe()\n",
    "\n",
    "# View results\n",
    "print(rides_per_year_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "rides_per_month_query = \"\"\"\n",
    "                        SELECT EXTRACT(MONTH FROM trip_start_timestamp) AS month, \n",
    "                               COUNT(1) AS num_trips\n",
    "                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                        WHERE EXTRACT(YEAR FROM trip_start_timestamp) = 2017\n",
    "                        GROUP BY month\n",
    "                        ORDER BY month\n",
    "                        \"\"\"\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "rides_per_month_query_job = client.query(rides_per_month_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "rides_per_month_result = rides_per_month_query_job.to_dataframe()\n",
    "\n",
    "# View results\n",
    "print(rides_per_month_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_query = \"\"\"\n",
    "               WITH RelevantRides AS\n",
    "               (\n",
    "                   SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day, \n",
    "                          trip_miles, \n",
    "                          trip_seconds\n",
    "                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                   WHERE trip_start_timestamp > '2017-01-01' AND \n",
    "                         trip_start_timestamp < '2017-07-01' AND \n",
    "                         trip_seconds > 0 AND \n",
    "                         trip_miles > 0\n",
    "               )\n",
    "               SELECT hour_of_day, \n",
    "                      COUNT(1) AS num_trips, \n",
    "                      3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph\n",
    "               FROM RelevantRides\n",
    "               GROUP BY hour_of_day\n",
    "               ORDER BY hour_of_day\n",
    "               \"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "speeds_query_job = client.query(speeds_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "speeds_result = speeds_query_job.to_dataframe()\n",
    "\n",
    "# View results\n",
    "print(speeds_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"stackoverflow\" dataset\n",
    "dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of available tables \n",
    "tables = list(client.list_tables(dataset))\n",
    "list_of_tables = [table.table_id for table in tables] \n",
    "\n",
    "# Print your answer\n",
    "print(list_of_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"posts_answers\" table\n",
    "answers_table_ref = dataset_ref.table(\"posts_answers\")\n",
    "\n",
    "# API request - fetch the table\n",
    "answers_table = client.get_table(answers_table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"posts_answers\" table\n",
    "client.list_rows(answers_table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"posts_questions\" table\n",
    "questions_table_ref = dataset_ref.table(\"posts_questions\")\n",
    "\n",
    "# API request - fetch the table\n",
    "questions_table = client.get_table(questions_table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"posts_questions\" table\n",
    "client.list_rows(questions_table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "questions_query = \"\"\"\n",
    "                  SELECT id, title, owner_user_id\n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "                  WHERE tags LIKE '%bigquery%'\n",
    "                  \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "questions_query_job = client.query(questions_query, job_config=safe_config) # Your code goes here\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "questions_results = questions_query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "# Preview results\n",
    "print(questions_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "answers_query = \"\"\"\n",
    "                SELECT a.id, a.body, a.owner_user_id\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n",
    "                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                    ON q.id = a.parent_id\n",
    "                WHERE q.tags LIKE '%bigquery%'\n",
    "                \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "answers_query_job = client.query(answers_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "answers_results = answers_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(answers_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "bigquery_experts_query = \"\"\"\n",
    "                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                             ON q.id = a.parent_Id\n",
    "                         WHERE q.tags LIKE '%bigquery%'\n",
    "                         GROUP BY a.owner_user_id\n",
    "                         \"\"\"\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "bigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "bigquery_experts_results = bigquery_experts_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(bigquery_experts_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOIN and UNION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"stackoverflow\" dataset\n",
    "dataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"posts_questions\" table\n",
    "table_ref = dataset_ref.table(\"posts_questions\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"posts_answers\" table\n",
    "table_ref = dataset_ref.table(\"posts_answers\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_query = \"\"\"\n",
    "              SELECT q.id AS q_id,\n",
    "                  MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer\n",
    "              FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                  INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "              ON q.id = a.parent_id\n",
    "              WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01'\n",
    "              GROUP BY q_id\n",
    "              ORDER BY time_to_answer\n",
    "              \"\"\"\n",
    "\n",
    "first_result = client.query(first_query).result().to_dataframe()\n",
    "print(\"Percentage of answered questions: %s%%\" % \\\n",
    "      (sum(first_result[\"time_to_answer\"].notnull()) / len(first_result) * 100))\n",
    "print(\"Number of questions:\", len(first_result))\n",
    "first_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "correct_query = \"\"\"\n",
    "                SELECT q.id AS q_id,\n",
    "                    MIN(TIMESTAMP_DIFF(a.creation_date, q.creation_date, SECOND)) as time_to_answer\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                    LEFT JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                ON q.id = a.parent_id\n",
    "                WHERE q.creation_date >= '2018-01-01' and q.creation_date < '2018-02-01'\n",
    "                GROUP BY q_id\n",
    "                ORDER BY time_to_answer\n",
    "                \"\"\"\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()\n",
    "\n",
    "# Run the query, and return a pandas DataFrame\n",
    "correct_result = client.query(correct_query).result().to_dataframe()\n",
    "print(\"Percentage of answered questions: %s%%\" % \\\n",
    "      (sum(correct_result[\"time_to_answer\"].notnull()) / len(correct_result) * 100))\n",
    "print(\"Number of questions:\", len(correct_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "q_and_a_query = \"\"\"\n",
    "                SELECT q.owner_user_id AS owner_user_id,\n",
    "                    MIN(q.creation_date) AS q_creation_date,\n",
    "                    MIN(a.creation_date) AS a_creation_date\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                    RIGHT JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                ON q.owner_user_id = a.owner_user_id \n",
    "                WHERE q.creation_date >= '2019-01-01' AND q.creation_date < '2019-02-01' \n",
    "                    AND a.creation_date >= '2019-01-01' AND a.creation_date < '2019-02-01'\n",
    "                GROUP BY owner_user_id\n",
    "                \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "three_tables_query = \"\"\"\n",
    "                     SELECT u.id AS id,\n",
    "                         MIN(q.creation_date) AS q_creation_date,\n",
    "                         MIN(a.creation_date) AS a_creation_date\n",
    "                     FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                         FULL JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                             ON q.owner_user_id = a.owner_user_id \n",
    "                         RIGHT JOIN `bigquery-public-data.stackoverflow.users` AS u\n",
    "                             ON q.owner_user_id = u.id\n",
    "                     WHERE u.creation_date >= '2019-01-01' and u.creation_date < '2019-02-01'\n",
    "                     GROUP BY id\n",
    "                     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "all_users_query = \"\"\"\n",
    "                  SELECT q.owner_user_id \n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                  WHERE EXTRACT(DATE FROM q.creation_date) = '2019-01-01'\n",
    "                  UNION DISTINCT\n",
    "                  SELECT a.owner_user_id\n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                  WHERE EXTRACT(DATE FROM a.creation_date) = '2019-01-01'\n",
    "                  \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"chicago_taxi_trips\" dataset\n",
    "dataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"taxi_trips\" table\n",
    "table_ref = dataset_ref.table(\"taxi_trips\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the blank below\n",
    "avg_num_trips_query = \"\"\"\n",
    "                      WITH trips_by_day AS\n",
    "                      (\n",
    "                      SELECT DATE(trip_start_timestamp) AS trip_date,\n",
    "                          COUNT(*) as num_trips\n",
    "                      FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                      WHERE trip_start_timestamp >= '2016-01-01' AND trip_start_timestamp < '2018-01-01'\n",
    "                      GROUP BY trip_date\n",
    "                      ORDER BY trip_date\n",
    "                      )\n",
    "                      SELECT trip_date,\n",
    "                          AVG(num_trips) \n",
    "                          OVER (\n",
    "                               ORDER BY trip_date\n",
    "                               ROWS BETWEEN 15 PRECEDING AND 15 FOLLOWING\n",
    "                               ) AS avg_num_trips\n",
    "                      FROM trips_by_day\n",
    "                      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amend the query below\n",
    "trip_number_query = \"\"\"\n",
    "                    SELECT pickup_community_area,\n",
    "                        trip_start_timestamp,\n",
    "                        trip_end_timestamp,\n",
    "                        RANK() \n",
    "                            OVER (\n",
    "                                  PARTITION BY pickup_community_area\n",
    "                                  ORDER BY trip_start_timestamp\n",
    "                                  ) AS trip_number\n",
    "                    FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                    WHERE DATE(trip_start_timestamp) = '2017-05-01'\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the blanks below\n",
    "break_time_query = \"\"\"\n",
    "                   SELECT taxi_id,\n",
    "                       trip_start_timestamp,\n",
    "                       trip_end_timestamp,\n",
    "                       TIMESTAMP_DIFF(\n",
    "                           trip_start_timestamp, \n",
    "                           LAG(trip_end_timestamp, 1) OVER (PARTITION BY taxi_id ORDER BY trip_start_timestamp), \n",
    "                           MINUTE) as prev_break\n",
    "                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                   WHERE DATE(trip_start_timestamp) = '2017-05-01' \n",
    "                   \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested and Repeated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"github_repos\" dataset\n",
    "dataset_ref = client.dataset(\"github_repos\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construct a reference to the \"sample_commits\" table\n",
    "table_ref = dataset_ref.table(\"sample_commits\")\n",
    "\n",
    "# API request - fetch the table\n",
    "sample_commits_table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(sample_commits_table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query to find the answer\n",
    "max_commits_query = \"\"\"\n",
    "                    SELECT committer.name AS committer_name, COUNT(*) AS num_commits\n",
    "                    FROM `bigquery-public-data.github_repos.sample_commits`\n",
    "                    WHERE committer.date >= '2016-01-01' AND committer.date < '2017-01-01'\n",
    "                    GROUP BY committer_name\n",
    "                    ORDER BY num_commits DESC \n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a reference to the \"languages\" table\n",
    "table_ref = dataset_ref.table(\"languages\")\n",
    "\n",
    "# API request - fetch the table\n",
    "languages_table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the table\n",
    "client.list_rows(languages_table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query to find the answer\n",
    "pop_lang_query = \"\"\"\n",
    "                 SELECT l.name AS language_name,COUNT(*) AS num_repos\n",
    "                 FROM `bigquery-public-data.github_repos.languages`, UNNEST(language) AS l\n",
    "                 GROUP BY language_name\n",
    "                 ORDER BY num_repos DESC                 \n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "all_langs_query = \"\"\"\n",
    "                  SELECT l.name AS name, l.bytes AS bytes\n",
    "                  FROM `bigquery-public-data.github_repos.languages`, UNNEST(language) AS l\n",
    "                  WHERE repo_name = 'polyrabbit/polyglot'\n",
    "                  ORDER BY bytes DESC\n",
    "                  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
